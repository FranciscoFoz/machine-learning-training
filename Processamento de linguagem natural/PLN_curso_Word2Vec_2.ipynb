{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Word2Vec: treinamento de Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explorando o Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv('/home/franciscofoz/Documents/GitHub/machine-learning-training/Processamento de linguagem natural/Datasets/w2v3_treino.csv')\n",
    "df_teste = pd.read_csv('/home/franciscofoz/Documents/GitHub/machine-learning-training/Processamento de linguagem natural/Datasets/w2v3_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>Mural: Há 30 anos, aeroporto não foi bem receb...</td>\n",
       "      <td>Década de 1970. Congonhas já estava superlotad...</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>As notícias sobre Schumacher não são boas, diz...</td>\n",
       "      <td>O ex-presidente da Ferrari Luca di Montezemolo...</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>esporte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/esporte/2016/02/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>De olho em R$ 50 bilhões, governo pode concede...</td>\n",
       "      <td>Para fazer caixa, o governo estuda conceder pa...</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Moro deu a Lula o papel de coitadinho</td>\n",
       "      <td>Realizou-se parcialmente o primeiro objetivo d...</td>\n",
       "      <td>2016-06-03</td>\n",
       "      <td>colunas</td>\n",
       "      <td>eliogaspari</td>\n",
       "      <td>http://www1.folha.uol.com.br/colunas/eliogaspa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>Velocidade da aprovação das reformas tem 'exce...</td>\n",
       "      <td>O Banco Central afirmou que a velocidade da ap...</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2016/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1      Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2      Apesar de larga vitória nas legislativas, Macr...   \n",
       "3      Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4      Após queda em maio, a atividade econômica sobe...   \n",
       "...                                                  ...   \n",
       "89995  Mural: Há 30 anos, aeroporto não foi bem receb...   \n",
       "89996  As notícias sobre Schumacher não são boas, diz...   \n",
       "89997  De olho em R$ 50 bilhões, governo pode concede...   \n",
       "89998              Moro deu a Lula o papel de coitadinho   \n",
       "89999  Velocidade da aprovação das reformas tem 'exce...   \n",
       "\n",
       "                                                    text        date  \\\n",
       "0      A candidata da direita nacionalista à Presidên...  2017-04-28   \n",
       "1      O centrista independente Emmanuel Macron e a d...  2017-04-23   \n",
       "2      As eleições legislativas deste domingo (19) na...  2017-06-19   \n",
       "3      O número de ocorrências de homicídios dolosos ...  2015-07-24   \n",
       "4      A economia cresceu 0,25% no segundo trimestre,...  2017-08-17   \n",
       "...                                                  ...         ...   \n",
       "89995  Década de 1970. Congonhas já estava superlotad...  2015-01-22   \n",
       "89996  O ex-presidente da Ferrari Luca di Montezemolo...  2016-04-02   \n",
       "89997  Para fazer caixa, o governo estuda conceder pa...  2017-08-29   \n",
       "89998  Realizou-se parcialmente o primeiro objetivo d...  2016-06-03   \n",
       "89999  O Banco Central afirmou que a velocidade da ap...  2016-10-25   \n",
       "\n",
       "        category  subcategory  \\\n",
       "0          mundo          NaN   \n",
       "1          mundo          NaN   \n",
       "2          mundo          NaN   \n",
       "3      cotidiano          NaN   \n",
       "4        mercado          NaN   \n",
       "...          ...          ...   \n",
       "89995  cotidiano          NaN   \n",
       "89996    esporte          NaN   \n",
       "89997    mercado          NaN   \n",
       "89998    colunas  eliogaspari   \n",
       "89999    mercado          NaN   \n",
       "\n",
       "                                                    link  \n",
       "0      http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1      http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2      http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3      http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4      http://www1.folha.uol.com.br/mercado/2017/08/1...  \n",
       "...                                                  ...  \n",
       "89995  http://www1.folha.uol.com.br/cotidiano/2015/01...  \n",
       "89996  http://www1.folha.uol.com.br/esporte/2016/02/1...  \n",
       "89997  http://www1.folha.uol.com.br/mercado/2017/08/1...  \n",
       "89998  http://www1.folha.uol.com.br/colunas/eliogaspa...  \n",
       "89999  http://www1.folha.uol.com.br/mercado/2016/10/1...  \n",
       "\n",
       "[90000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:06:29.816245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Rio de Janeiro é uma cidade maravilhosa'\n",
    "doc = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rio"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Rio de Janeiro,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pré processamento com Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_para_tratamento = (titulos.lower() for titulos in df_treino.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_textos(doc):\n",
    "    \n",
    "    tokens_validos = list()\n",
    "    \n",
    "    for token in doc:\n",
    "        eh_valido = not token.is_stop and token.is_alpha\n",
    "        if eh_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "            \n",
    "    if len(tokens_validos) > 2:\n",
    "        return ' '.join(tokens_validos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rio Janeiro cidade maravilhosa'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trata_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.732930342356364\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(texto_para_tratamentos,batch_size=1000,n_process= -1)]\n",
    "\n",
    "tf = time() - t0\n",
    "\n",
    "print(tf/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_tratados = pd.DataFrame({'titulos':textos_tratados})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>mural há anos aeroporto recebido moradores gua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>notícias schumacher boas ferrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>olho bilhões governo conceder áreas petróleo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>moro deu lula papel coitadinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>velocidade aprovação reformas excedido expecta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titulos\n",
       "0      polêmica marine le pen abomina negacionistas h...\n",
       "1      macron le pen turno frança revés siglas tradic...\n",
       "2      apesar larga vitória legislativas macron terá ...\n",
       "3      governo antecipa balanço alckmin anuncia queda...\n",
       "4           queda maio atividade econômica sobe junho bc\n",
       "...                                                  ...\n",
       "89995  mural há anos aeroporto recebido moradores gua...\n",
       "89996                   notícias schumacher boas ferrari\n",
       "89997       olho bilhões governo conceder áreas petróleo\n",
       "89998                     moro deu lula papel coitadinho\n",
       "89999  velocidade aprovação reformas excedido expecta...\n",
       "\n",
       "[90000 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hiperparâmetros do Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "w2v_modelo = Word2Vec(sg=0,\n",
    "                      window=2,\n",
    "                      vector_size=300,\n",
    "                      min_count=5,\n",
    "                      alpha=0.03,\n",
    "                      min_alpha=0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens = [titulo.split(' ') for titulo in titulos_tratados.titulos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 21:16:43,943 : - collecting all words and their counts\n",
      "2024-04-26 21:16:43,944 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-04-26 21:16:43,963 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2024-04-26 21:16:43,991 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2024-04-26 21:16:44,011 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2024-04-26 21:16:44,026 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2024-04-26 21:16:44,059 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2024-04-26 21:16:44,084 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2024-04-26 21:16:44,116 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2024-04-26 21:16:44,147 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2024-04-26 21:16:44,159 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2024-04-26 21:16:44,182 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2024-04-26 21:16:44,196 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2024-04-26 21:16:44,245 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2024-04-26 21:16:44,255 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2024-04-26 21:16:44,268 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2024-04-26 21:16:44,287 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2024-04-26 21:16:44,311 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2024-04-26 21:16:44,332 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2024-04-26 21:16:44,336 : - Creating a fresh vocabulary\n",
      "2024-04-26 21:16:44,499 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.56% of original 39693, drops 26769)', 'datetime': '2024-04-26T21:16:44.499028', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-04-26 21:16:44,501 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.67% of original 540242, drops 45019)', 'datetime': '2024-04-26T21:16:44.501903', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-04-26 21:16:44,657 : - deleting the raw counts dictionary of 39693 items\n",
      "2024-04-26 21:16:44,659 : - sample=0.001 downsamples 8 most-common words\n",
      "2024-04-26 21:16:44,661 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2024-04-26T21:16:44.661222', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-04-26 21:16:44,666 : - sorting after vectors have been allocated is expensive & error-prone\n",
      "2024-04-26 21:16:44,869 : - estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
      "2024-04-26 21:16:44,870 : - resetting layer weights\n",
      "2024-04-26 21:16:44,873 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-04-26T21:16:44.873420', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : - %(message)s',level = logging.INFO)\n",
    "\n",
    "w2v_modelo.build_vocab(lista_lista_tokens,progress_per=5000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Treinamento do Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 21:19:35,053 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-04-26T21:19:35.053758', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2024-04-26 21:19:36,100 : - EPOCH 0 - PROGRESS: at 88.85% examples, 420424 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-26 21:19:36,226 : - EPOCH 0: training on 540242 raw words (486174 effective words) took 1.2s, 421452 effective words/s\n",
      "2024-04-26 21:19:37,257 : - EPOCH 1 - PROGRESS: at 96.22% examples, 464359 words/s, in_qsize 3, out_qsize 0\n",
      "2024-04-26 21:19:37,264 : - EPOCH 1: training on 540242 raw words (486200 effective words) took 1.0s, 479086 effective words/s\n",
      "2024-04-26 21:19:38,097 : - EPOCH 2: training on 540242 raw words (486185 effective words) took 0.8s, 597026 effective words/s\n",
      "2024-04-26 21:19:39,075 : - EPOCH 3: training on 540242 raw words (486067 effective words) took 1.0s, 500838 effective words/s\n",
      "2024-04-26 21:19:40,125 : - EPOCH 4 - PROGRESS: at 72.19% examples, 339949 words/s, in_qsize 6, out_qsize 0\n",
      "2024-04-26 21:19:40,373 : - EPOCH 4: training on 540242 raw words (486130 effective words) took 1.3s, 379990 effective words/s\n",
      "2024-04-26 21:19:41,204 : - EPOCH 5: training on 540242 raw words (486107 effective words) took 0.8s, 594631 effective words/s\n",
      "2024-04-26 21:19:41,935 : - EPOCH 6: training on 540242 raw words (486016 effective words) took 0.7s, 670779 effective words/s\n",
      "2024-04-26 21:19:42,682 : - EPOCH 7: training on 540242 raw words (486031 effective words) took 0.7s, 657669 effective words/s\n",
      "2024-04-26 21:19:43,409 : - EPOCH 8: training on 540242 raw words (486164 effective words) took 0.7s, 674548 effective words/s\n",
      "2024-04-26 21:19:44,252 : - EPOCH 9: training on 540242 raw words (486116 effective words) took 0.8s, 582538 effective words/s\n",
      "2024-04-26 21:19:45,119 : - EPOCH 10: training on 540242 raw words (486245 effective words) took 0.9s, 567953 effective words/s\n",
      "2024-04-26 21:19:45,946 : - EPOCH 11: training on 540242 raw words (486142 effective words) took 0.8s, 592799 effective words/s\n",
      "2024-04-26 21:19:46,682 : - EPOCH 12: training on 540242 raw words (486143 effective words) took 0.7s, 666363 effective words/s\n",
      "2024-04-26 21:19:47,448 : - EPOCH 13: training on 540242 raw words (486145 effective words) took 0.8s, 640587 effective words/s\n",
      "2024-04-26 21:19:48,187 : - EPOCH 14: training on 540242 raw words (486195 effective words) took 0.7s, 668678 effective words/s\n",
      "2024-04-26 21:19:48,887 : - EPOCH 15: training on 540242 raw words (486198 effective words) took 0.7s, 701281 effective words/s\n",
      "2024-04-26 21:19:49,577 : - EPOCH 16: training on 540242 raw words (486252 effective words) took 0.7s, 711832 effective words/s\n",
      "2024-04-26 21:19:50,281 : - EPOCH 17: training on 540242 raw words (486177 effective words) took 0.7s, 698605 effective words/s\n",
      "2024-04-26 21:19:50,972 : - EPOCH 18: training on 540242 raw words (486058 effective words) took 0.7s, 712349 effective words/s\n",
      "2024-04-26 21:19:51,713 : - EPOCH 19: training on 540242 raw words (486145 effective words) took 0.7s, 664131 effective words/s\n",
      "2024-04-26 21:19:52,428 : - EPOCH 20: training on 540242 raw words (486118 effective words) took 0.7s, 694778 effective words/s\n",
      "2024-04-26 21:19:53,142 : - EPOCH 21: training on 540242 raw words (486083 effective words) took 0.7s, 689884 effective words/s\n",
      "2024-04-26 21:19:53,844 : - EPOCH 22: training on 540242 raw words (486231 effective words) took 0.7s, 699964 effective words/s\n",
      "2024-04-26 21:19:54,548 : - EPOCH 23: training on 540242 raw words (486226 effective words) took 0.7s, 697932 effective words/s\n",
      "2024-04-26 21:19:55,244 : - EPOCH 24: training on 540242 raw words (486205 effective words) took 0.7s, 714094 effective words/s\n",
      "2024-04-26 21:19:55,941 : - EPOCH 25: training on 540242 raw words (486079 effective words) took 0.7s, 705017 effective words/s\n",
      "2024-04-26 21:19:56,645 : - EPOCH 26: training on 540242 raw words (486135 effective words) took 0.7s, 697347 effective words/s\n",
      "2024-04-26 21:19:57,323 : - EPOCH 27: training on 540242 raw words (486206 effective words) took 0.7s, 725081 effective words/s\n",
      "2024-04-26 21:19:58,021 : - EPOCH 28: training on 540242 raw words (486202 effective words) took 0.7s, 706969 effective words/s\n",
      "2024-04-26 21:19:58,702 : - EPOCH 29: training on 540242 raw words (486015 effective words) took 0.7s, 724529 effective words/s\n",
      "2024-04-26 21:19:58,703 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584390 effective words) took 23.6s, 616742 effective words/s', 'datetime': '2024-04-26T21:19:58.703486', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-28-generic-x86_64-with-glibc2.35', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584390, 16207260)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens,\n",
    "                 total_examples=w2v_modelo.corpus_count,\n",
    "                 epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aliança', 0.36559873819351196),\n",
       " ('hugh', 0.3606097996234894),\n",
       " ('criador', 0.35564297437667847),\n",
       " ('playboy', 0.34625309705734253),\n",
       " ('cosac', 0.34071919322013855),\n",
       " ('dublador', 0.33473655581474304),\n",
       " ('allen', 0.3341161608695984),\n",
       " ('filósofa', 0.3315010964870453),\n",
       " ('law', 0.33079516887664795),\n",
       " ('cards', 0.32965970039367676)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar('revista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romance', 0.4368336796760559),\n",
       " ('biografia', 0.4339773654937744),\n",
       " ('livros', 0.407418817281723),\n",
       " ('virginia', 0.40444430708885193),\n",
       " ('memórias', 0.40106022357940674),\n",
       " ('autobiografia', 0.3997996747493744),\n",
       " ('automóvel', 0.3987919092178345),\n",
       " ('coletânea', 0.39591890573501587),\n",
       " ('antologia', 0.38114482164382935),\n",
       " ('álbuns', 0.37838220596313477)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar('livro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cultivo', 0.5499607920646667),\n",
       " ('firmam', 0.4404166638851166),\n",
       " ('culinária', 0.43562230467796326),\n",
       " ('homicídios', 0.4202877879142761),\n",
       " ('publicados', 0.4139198660850525),\n",
       " ('hidrelétricas', 0.4076575040817261),\n",
       " ('gastronomia', 0.4067721366882324),\n",
       " ('acumulado', 0.40170738101005554),\n",
       " ('açúcar', 0.4001285433769226),\n",
       " ('assinantes', 0.3992401361465454)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar('coca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('viúva', 0.4742732346057892),\n",
       " ('orson', 0.4596574008464813),\n",
       " ('agressor', 0.4594123363494873),\n",
       " ('valter', 0.441806823015213),\n",
       " ('monólogo', 0.43999508023262024),\n",
       " ('banal', 0.435576468706131),\n",
       " ('cauã', 0.435467392206192),\n",
       " ('lou', 0.43429383635520935),\n",
       " ('eisenstein', 0.4333285093307495),\n",
       " ('dela', 0.43278568983078003)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar('gato')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
