{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: regex e modelos de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.read_csv('/home/franciscofoz/Documents/GitHub/machine-learning-training/Processamento de linguagem natural/Datasets/stackoverflow_ingles.csv')\n",
    "df_esp = pd.read_csv('/home/franciscofoz/Documents/GitHub/machine-learning-training/Processamento de linguagem natural/Datasets/stackoverflow_espanhol.csv')\n",
    "df_ptbr = pd.read_csv('/home/franciscofoz/Documents/GitHub/machine-learning-training/Processamento de linguagem natural/Datasets/stackoverflow_portugues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questao_eng = df_eng['Questão'][0]\n",
    "questao_esp = df_esp['Questão'][0]\n",
    "questao_ptbr = df_ptbr['Questão'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Se eu fizer o <em><a href=\"http://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_de_embaralhamento_criptogr%C3%A1fico\" rel=\"noreferrer\">hash</a></em> de senhas antes de armazená-las em meu banco de dados é suficiente para evitar que elas sejam recuperadas por alguém?</p>\n",
      "\n",
      "<p>Estou falando apenas da recuperação diretamente do banco de dados e não qualquer outro tipo de ataque, como <a href=\"http://pt.wikipedia.org/wiki/Ataque_de_for%C3%A7a_bruta\" rel=\"noreferrer\">força bruta</a> na página de login da aplicação, <em><a href=\"http://pt.wikipedia.org/wiki/Keylogger\" rel=\"noreferrer\">keylogger</a></em> no cliente e <a href=\"http://pt.wikipedia.org/wiki/Criptoan%C3%A1lise_de_mangueira_de_borracha\" rel=\"noreferrer\">criptoanálise <em>rubberhose</em></a>. Qualquer forma de <em>hash</em> não vai impedir esses ataques.</p>\n",
      "\n",
      "<p>Tenho preocupação em dificultar ou até impossibilitar a obtenção das senhas originais caso o banco de dados seja comprometido. Como dar maior garantia de segurança neste aspecto?</p>\n",
      "\n",
      "<p>Quais preocupações adicionais evitariam o acesso às senhas? Existem formas melhores de fazer esse <em>hash</em>?</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(questao_ptbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>',\n",
       " '<em>',\n",
       " '<a href=\"http://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_de_embaralhamento_criptogr%C3%A1fico\" rel=\"noreferrer\">',\n",
       " '</a>',\n",
       " '</em>',\n",
       " '</p>',\n",
       " '<p>',\n",
       " '<a href=\"http://pt.wikipedia.org/wiki/Ataque_de_for%C3%A7a_bruta\" rel=\"noreferrer\">',\n",
       " '</a>',\n",
       " '<em>',\n",
       " '<a href=\"http://pt.wikipedia.org/wiki/Keylogger\" rel=\"noreferrer\">',\n",
       " '</a>',\n",
       " '</em>',\n",
       " '<a href=\"http://pt.wikipedia.org/wiki/Criptoan%C3%A1lise_de_mangueira_de_borracha\" rel=\"noreferrer\">',\n",
       " '<em>',\n",
       " '</em>',\n",
       " '</a>',\n",
       " '<em>',\n",
       " '</em>',\n",
       " '</p>',\n",
       " '<p>',\n",
       " '</p>',\n",
       " '<p>',\n",
       " '<em>',\n",
       " '</em>',\n",
       " '</p>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'<.*?>',questao_ptbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eu fizer o hash de senhas antes de armazená-las em meu banco de dados é suficiente para evitar que elas sejam recuperadas por alguém?\n",
      "\n",
      "Estou falando apenas da recuperação diretamente do banco de dados e não qualquer outro tipo de ataque, como força bruta na página de login da aplicação, keylogger no cliente e criptoanálise rubberhose. Qualquer forma de hash não vai impedir esses ataques.\n",
      "\n",
      "Tenho preocupação em dificultar ou até impossibilitar a obtenção das senhas originais caso o banco de dados seja comprometido. Como dar maior garantia de segurança neste aspecto?\n",
      "\n",
      "Quais preocupações adicionais evitariam o acesso às senhas? Existem formas melhores de fazer esse hash?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r'<.*?>','',questao_ptbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(textos,regex):\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex.sub('',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex.sub('',textos) for texto in textos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_html = re.compile(r'<.*?>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eu fizer o hash de senhas antes de armazená-las em meu banco de dados é suficiente para evitar que elas sejam recuperadas por alguém?\n",
      "\n",
      "Estou falando apenas da recuperação diretamente do banco de dados e não qualquer outro tipo de ataque, como força bruta na página de login da aplicação, keylogger no cliente e criptoanálise rubberhose. Qualquer forma de hash não vai impedir esses ataques.\n",
      "\n",
      "Tenho preocupação em dificultar ou até impossibilitar a obtenção das senhas originais caso o banco de dados seja comprometido. Como dar maior garantia de segurança neste aspecto?\n",
      "\n",
      "Quais preocupações adicionais evitariam o acesso às senhas? Existem formas melhores de fazer esse hash?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remover(questao_ptbr,regex_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las sentencias dinámicas son sentencias SQL que se crean como cadenas de texto (strings) y en las que se insertan/concatenan valores obtenidos de alguna fuente (normalmente proveniente del usuario), lo que puede hacer que sean vulnerables a inyección SQL si no se sanean las entradas, como por ejemplo:\n",
      "\n",
      "$id_usuario = $_POST[\"id\"];\n",
      "\n",
      "mysql_query(\"SELECT * FROM usuarios WHERE id = $id_usuario\");\n",
      "\n",
      "\n",
      "Eso es un ejemplo de una vulnerabilidad grave en la seguridad de una aplicación (web o no) porque si el usuario introdujese un valor como 1; DROP TABLE usuarios;-- nos encontraríamos con que la sentencia ejecutada sería:\n",
      "\n",
      "SELECT * FROM usuarios WHERE id = 1; DROP TABLE usuarios;--\n",
      "\n",
      "\n",
      "Y se eliminaría la tabla Usuarios con todos los datos contenidos en ella. \n",
      "\n",
      "¿Cómo puedo evitar que la inyección SQL ocurra en PHP?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remover(questao_esp,regex_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a piece of C++ code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster.\n",
      "\n",
      "#include &lt;algorithm&gt;\n",
      "#include &lt;ctime&gt;\n",
      "#include &lt;iostream&gt;\n",
      "\n",
      "int main()\n",
      "{\n",
      "    // Generate data\n",
      "    const unsigned arraySize = 32768;\n",
      "    int data[arraySize];\n",
      "\n",
      "    for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        data[c] = std::rand() % 256;\n",
      "\n",
      "    // !!! With this, the next loop runs faster\n",
      "    std::sort(data, data + arraySize);\n",
      "\n",
      "    // Test\n",
      "    clock_t start = clock();\n",
      "    long long sum = 0;\n",
      "\n",
      "    for (unsigned i = 0; i &lt; 100000; ++i)\n",
      "    {\n",
      "        // Primary loop\n",
      "        for (unsigned c = 0; c &lt; arraySize; ++c)\n",
      "        {\n",
      "            if (data[c] &gt;= 128)\n",
      "                sum += data[c];\n",
      "        }\n",
      "    }\n",
      "\n",
      "    double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC;\n",
      "\n",
      "    std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl;\n",
      "    std::cout &lt;&lt; \"sum = \" &lt;&lt; sum &lt;&lt; std::endl;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Without std::sort(data, data + arraySize);, the code runs in 11.54 seconds.\n",
      "With the sorted data, the code runs in 1.93 seconds.\n",
      "\n",
      "\n",
      "Initially, I thought this might be just a language or compiler anomaly. So I tried it in Java.\n",
      "\n",
      "import java.util.Arrays;\n",
      "import java.util.Random;\n",
      "\n",
      "public class Main\n",
      "{\n",
      "    public static void main(String[] args)\n",
      "    {\n",
      "        // Generate data\n",
      "        int arraySize = 32768;\n",
      "        int data[] = new int[arraySize];\n",
      "\n",
      "        Random rnd = new Random(0);\n",
      "        for (int c = 0; c &lt; arraySize; ++c)\n",
      "            data[c] = rnd.nextInt() % 256;\n",
      "\n",
      "        // !!! With this, the next loop runs faster\n",
      "        Arrays.sort(data);\n",
      "\n",
      "        // Test\n",
      "        long start = System.nanoTime();\n",
      "        long sum = 0;\n",
      "\n",
      "        for (int i = 0; i &lt; 100000; ++i)\n",
      "        {\n",
      "            // Primary loop\n",
      "            for (int c = 0; c &lt; arraySize; ++c)\n",
      "            {\n",
      "                if (data[c] &gt;= 128)\n",
      "                    sum += data[c];\n",
      "            }\n",
      "        }\n",
      "\n",
      "        System.out.println((System.nanoTime() - start) / 1000000000.0);\n",
      "        System.out.println(\"sum = \" + sum);\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "With a somewhat similar but less extreme result.\n",
      "\n",
      "\n",
      "\n",
      "My first thought was that sorting brings the data into the cache, but then I thought how silly that is because the array was just generated.\n",
      "\n",
      "\n",
      "What is going on?\n",
      "Why is it faster to process a sorted array than an unsorted array?\n",
      "The code is summing up some independent terms, and the order should not matter.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remover(questao_eng,regex_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_codigo(textos,regex):\n",
    "    \n",
    "    regex_codigo = re.compile(r'<code>(.|(\\n))*?</code>')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex.sub('CODE',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex.sub('CODE',textos) for texto in textos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_codigo = re.compile(r'<code>(.|(\\n))*?</code>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Here is a piece of C++ code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster.</p>\n",
      "\n",
      "<pre class=\"lang-cpp prettyprint-override\">CODE</pre>\n",
      "\n",
      "<ul>\n",
      "<li>Without CODE, the code runs in 11.54 seconds.</li>\n",
      "<li>With the sorted data, the code runs in 1.93 seconds.</li>\n",
      "</ul>\n",
      "\n",
      "<p>Initially, I thought this might be just a language or compiler anomaly. So I tried it in Java.</p>\n",
      "\n",
      "<pre class=\"lang-java prettyprint-override\">CODE</pre>\n",
      "\n",
      "<p>With a somewhat similar but less extreme result.</p>\n",
      "\n",
      "<hr>\n",
      "\n",
      "<p>My first thought was that sorting brings the data into the cache, but then I thought how silly that is because the array was just generated.</p>\n",
      "\n",
      "<ul>\n",
      "<li>What is going on?</li>\n",
      "<li>Why is it faster to process a sorted array than an unsorted array?</li>\n",
      "<li>The code is summing up some independent terms, and the order should not matter.</li>\n",
      "</ul>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(substituir_codigo(questao_eng,regex_codigo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo de todo o banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_codigo(textos):\n",
    "    \n",
    "    regex_codigo = re.compile(r'<code>(.|(\\n))*?</code>')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex_codigo.sub('CODE',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex_codigo.sub('CODE',texto) for texto in textos]\n",
    "    \n",
    "\n",
    "def remover(textos):\n",
    "    \n",
    "    regex_html = re.compile(r'<.*?>')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex_html.sub('',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex_html.sub('',texto) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng['questao_sem_codigo_e_html'] = df_eng['Questão'].apply(substituir_codigo).apply(remover)\n",
    "df_esp['questao_sem_codigo_e_html'] = df_esp['Questão'].apply(substituir_codigo).apply(remover)\n",
    "df_ptbr['questao_sem_codigo_e_html'] = df_ptbr['Questão'].apply(substituir_codigo).apply(remover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo dígitos e caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minusculo(textos):\n",
    "    if type(textos) == str:\n",
    "        return textos.lower()\n",
    "    else:\n",
    "        return [texto.lower() for texto in textos]\n",
    "    \n",
    "    \n",
    "def remover_pontuacao(textos):\n",
    "    \n",
    "    regex_pontuacao = re.compile(r'[^\\w\\s]')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex_pontuacao.sub('',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex_pontuacao.sub('',texto) for texto in textos]\n",
    "    \n",
    "def remover_digitos(textos):\n",
    "    \n",
    "    regex_digitos = re.compile(r'\\d+')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex_digitos.sub('',textos)\n",
    "    \n",
    "    else:\n",
    "        return [regex_digitos.sub('',texto) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng['questao_sem_digitos_e_pontuacao'] = df_eng['questao_sem_codigo_e_html'].apply(minusculo).apply(remover_pontuacao).apply(remover_digitos)\n",
    "df_esp['questao_sem_digitos_e_pontuacao'] = df_esp['questao_sem_codigo_e_html'].apply(minusculo).apply(remover_pontuacao).apply(remover_digitos)\n",
    "df_ptbr['questao_sem_digitos_e_pontuacao'] = df_ptbr['questao_sem_codigo_e_html'].apply(minusculo).apply(remover_pontuacao).apply(remover_digitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_por_espaco(textos):\n",
    "    \n",
    "    regex_espaco = re.compile(r' +')\n",
    "    regex_quebra_de_linha = re.compile(r' +\\n+')\n",
    "    \n",
    "    if type(textos) == str:\n",
    "        return regex_quebra_de_linha.sub(' ',regex_espaco.sub(' ',textos))\n",
    "    \n",
    "    else:\n",
    "        return [regex_quebra_de_linha.sub(' ',regex_espaco.sub(' ',texto)) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng['questao_tratamento_final'] = df_eng['questao_sem_digitos_e_pontuacao'].apply(minusculo).apply(substituir_por_espaco)\n",
    "df_esp['questao_tratamento_final'] = df_esp['questao_sem_digitos_e_pontuacao'].apply(minusculo).apply(substituir_por_espaco)\n",
    "df_ptbr['questao_tratamento_final'] = df_ptbr['questao_sem_digitos_e_pontuacao'].apply(minusculo).apply(substituir_por_espaco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenvolvendo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ptbr['idioma'] = 'ptbr'\n",
    "df_esp['idioma'] = 'esp'\n",
    "df_eng['idioma'] = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "port_treino, port_teste = train_test_split(df_ptbr['questao_tratamento_final'],test_size=0.2,random_state=123)\n",
    "eng_treino, eng_teste = train_test_split(df_eng['questao_tratamento_final'],test_size=0.2,random_state=123)\n",
    "esp_treino, esp_teste = train_test_split(df_esp['questao_tratamento_final'],test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_questoes_port = ' '.join(port_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "todas_palavras_port = WhitespaceTokenizer().tokenize(todas_questoes_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "\n",
    "port_treino_bigram, vocab_port = padded_everygram_pipeline(2,todas_palavras_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "modelo_port = MLE(2)\n",
    "modelo_port.fit(port_treino_bigram, vocab_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('n', 1161), ('r', 2334), ('</s>', 5790), ('b', 292), ('t', 554), ('i', 542), ('d', 1429), ('m', 887), ('z', 216), ('q', 66), ('s', 2052), ('l', 1373), ('g', 351), ('ç', 586), ('v', 294), ('p', 313), ('c', 399), ('j', 48), ('a', 6), ('u', 67), ('o', 120), ('x', 17), ('í', 20), ('f', 74), ('e', 5), ('ú', 1), ('y', 34), ('w', 1), ('k', 11), ('h', 1)])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import NgramCounter\n",
    "\n",
    "\n",
    "modelo_port.counts[['a']].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "texto = 'good morning'\n",
    "palavras = WhitespaceTokenizer().tokenize(texto)\n",
    "\n",
    "palavras_fakechar = [list(pad_both_ends(palavra,n=2)) for palavra in palavras]\n",
    "palavras_bigramns = [list(bigrams(palavra)) for palavra in palavras_fakechar]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<s>', 'g'), ('g', 'o'), ('o', 'o'), ('o', 'd'), ('d', '</s>')],\n",
       " [('<s>', 'm'),\n",
       "  ('m', 'o'),\n",
       "  ('o', 'r'),\n",
       "  ('r', 'n'),\n",
       "  ('n', 'i'),\n",
       "  ('i', 'n'),\n",
       "  ('n', 'g'),\n",
       "  ('g', '</s>')]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_bigramns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo_MLE(lista_textos):\n",
    "    todas_questoes = ' '.join(lista_textos)\n",
    "    todas_palavras = WhitespaceTokenizer().tokenize(todas_questoes)\n",
    "    bigrams,vocabulario = padded_everygram_pipeline(2,todas_palavras)\n",
    "    modelo = MLE(2)\n",
    "    modelo.fit(bigrams,vocabulario)\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_port = treinar_modelo_MLE(port_treino)\n",
    "modelo_eng = treinar_modelo_MLE(eng_treino)\n",
    "modelo_esp = treinar_modelo_MLE(esp_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.67178908687439\n",
      "21.535806001201696\n"
     ]
    }
   ],
   "source": [
    "for i in palavras_bigramns:\n",
    "    print(modelo_port.perplexity(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.26133308212415\n",
      "12.900755877319751\n"
     ]
    }
   ],
   "source": [
    "for i in palavras_bigramns:\n",
    "    print(modelo_eng.perplexity(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.15357126058061\n",
      "22.401851392617296\n"
     ]
    }
   ],
   "source": [
    "for i in palavras_bigramns:\n",
    "    print(modelo_esp.perplexity(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_perplexidade(modelo,texto):\n",
    "    \n",
    "    perplexidade = 0\n",
    "    palavras = WhitespaceTokenizer().tokenize(texto)\n",
    "    palavras_fakechar = [list(pad_both_ends(palavra,n=2)) for palavra in palavras]\n",
    "    palavras_bigramns = [list(bigrams(palavra)) for palavra in palavras_fakechar]\n",
    "    \n",
    "    for palavra in palavras_bigramns:\n",
    "        perplexidade += modelo.perplexity(palavra)\n",
    "        \n",
    "    return perplexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.1620889594439"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_eng,'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.20759508807609"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_port,'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.55542265319791"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_esp,'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204.3081162768985"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_port,df_ptbr['questao_sem_digitos_e_pontuacao'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_port,df_esp['questao_sem_digitos_e_pontuacao'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Lapace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo_lapace(lista_textos):\n",
    "    todas_questoes = ' '.join(lista_textos)\n",
    "    todas_palavras = WhitespaceTokenizer().tokenize(todas_questoes)\n",
    "    bigrams,vocabulario = padded_everygram_pipeline(2,todas_palavras)\n",
    "    modelo = Laplace(2)\n",
    "    modelo.fit(bigrams,vocabulario)\n",
    "    \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lapace_port = treinar_modelo_lapace(port_treino)\n",
    "modelo_lapace_eng = treinar_modelo_lapace(eng_treino)\n",
    "modelo_lapace_esp = treinar_modelo_lapace(esp_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1205.1526879433832"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_lapace_port,df_ptbr['questao_sem_digitos_e_pontuacao'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3118.19747480698"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_lapace_eng,df_ptbr['questao_sem_digitos_e_pontuacao'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203.8313026489946"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcular_perplexidade(modelo_lapace_esp,df_ptbr['questao_sem_digitos_e_pontuacao'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atribui_idioma(lista_texto):\n",
    "    \n",
    "    idioma = list()\n",
    "    for texto in lista_texto:\n",
    "        port = calcular_perplexidade(modelo_lapace_port,texto)\n",
    "        eng = calcular_perplexidade(modelo_lapace_eng,texto)\n",
    "        esp = calcular_perplexidade(modelo_lapace_esp,texto)\n",
    "        \n",
    "    if eng >= port <= esp:\n",
    "        idioma.append('portugues')\n",
    "    elif port >= eng <= esp:\n",
    "        idioma.append('ingles')\n",
    "    else:\n",
    "        idioma.append('espanhol')\n",
    "        \n",
    "    return idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['portugues']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atribui_idioma(port_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[portugues]    100\n",
       "Name: questao_tratamento_final, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_teste.apply(atribui_idioma).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
